<div align="center">

<pre>
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•—  â–ˆâ–ˆâ•—    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•— â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•â•â•â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â• â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â•â•
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—  
â•šâ•â•â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘     â–ˆâ–ˆâ•”â•â•â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ•”â•â•â•  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•  
â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘  â–ˆâ–ˆâ•‘    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—
â•šâ•â•â•â•â•â•â•â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•šâ•â•  â•šâ•â• â•šâ•â•â•â•â•â•â•šâ•â•  â•šâ•â•    â•šâ•â•â•â•â•â•â•â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â• â•šâ•â•â•šâ•â•  â•šâ•â•â•â•â•šâ•â•â•â•â•â•â•
                                                                                                    
</pre>

<blockquote>

<p align="center">
<!-- Consistent badge style: flat-square, with logos -->

<!-- Version, License -->
<img src="https://img.shields.io/badge/license-MIT-yellow?style=flat-square" alt="MIT License" />

<!-- Languages & Tools -->
<img src="https://img.shields.io/badge/Python-3.8+-3776AB?style=flat-square&logo=python&logoColor=white" alt="Python 3.8+" />
<img src="https://img.shields.io/badge/BeautifulSoup-4.9+-FF6B6B?style=flat-square&logo=python&logoColor=white" alt="BeautifulSoup4" />
<img src="https://img.shields.io/badge/Requests-HTTP-2E7D32?style=flat-square&logo=python&logoColor=white" alt="Requests" />

<!-- Libraries -->
<img src="https://img.shields.io/badge/TF--IDF-Algorithm-FF6B35?style=flat-square&logo=code&logoColor=white" alt="TF-IDF" />
<img src="https://img.shields.io/badge/JSON-Config-808080?style=flat-square&logo=json&logoColor=white" alt="JSON" />
<img src="https://img.shields.io/badge/Pytest-Testing-0A9EDC?style=flat-square&logo=pytest&logoColor=white" alt="Pytest" />

<!-- Features -->
<img src="https://img.shields.io/badge/Web-Crawler-FF6B6B?style=flat-square&logo=spider&logoColor=white" alt="Web Crawler" />



</p>

</blockquote>

</div>

# ğŸ” TechScope Search Engine â€” Python Web Crawler & Search Engine

<div align="center">

</div>

A complete search engine implementation with web crawling, TF-IDF indexing, and intelligent search capabilities.

## ğŸ¯ **Main Feature: Intelligent Search**

The core strength of TechScope is its **powerful search engine** that provides:

- **ğŸ” Smart Query Processing**: Advanced text analysis and tokenization
- **ğŸ“Š TF-IDF Scoring**: Sophisticated relevance ranking using Term Frequency-Inverse Document Frequency
- **âš¡ Fast Results**: Sub-100ms response times for typical queries
- **ğŸ¯ Accurate Ranking**: Cosine similarity algorithms for precise result ordering
- **ğŸ“± Interactive Mode**: Real-time search with immediate feedback

**Try it now:**
```sh
python main.py search "your search query"
```

## ğŸš€ Installation

Clone this repo and install dependencies:

```sh
git clone https://github.com/yourusername/TechScope-SearchEngine.git
cd TechScope-SearchEngine
pip install -r requirements.txt
```

## ğŸ“ Project Structure

```
TechScope-SearchEngine/
â”œâ”€â”€ crawler/                    # Web crawling components
â”‚   â””â”€â”€ crawler.py             # Main crawler implementation
â”œâ”€â”€ index/                      # Indexing and TF-IDF processing
â”‚   â”œâ”€â”€ indexer.py             # Main indexer
â”‚   â”œâ”€â”€ text_processor.py      # Text preprocessing
â”‚   â”œâ”€â”€ tfidf_calculator.py    # TF-IDF calculations
â”‚   â”œâ”€â”€ inverted_indexer.py    # Inverted index management
â”‚   â””â”€â”€ data/                  # Index storage
â”‚       â”œâ”€â”€ document_metadata.json
â”‚       â””â”€â”€ inverted_index.json
â”œâ”€â”€ query/                      # Search and query processing
â”‚   â”œâ”€â”€ query.py               # Main query engine
â”‚   â”œâ”€â”€ search_engine.py       # Search implementation
â”‚   â”œâ”€â”€ query_processor.py     # Query preprocessing
â”‚   â””â”€â”€ result_formatter.py    # Result formatting
â”œâ”€â”€ data/                       # Crawled web pages
â”‚   â””â”€â”€ pages/                 # HTML files and metadata
â”œâ”€â”€ Tests/                      # Comprehensive test suite
â”‚   â”œâ”€â”€ unit/                  # Unit tests
â”‚   â”œâ”€â”€ integration/           # Integration tests
â”‚   â”œâ”€â”€ performance/           # Performance tests
â”‚   â””â”€â”€ edge_cases/            # Edge case tests
â”œâ”€â”€ utils/                      # Utility functions
â”œâ”€â”€ main.py                     # Main application entry point
â”œâ”€â”€ config.json                 # Configuration settings
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                  # This file
```

## ğŸ› ï¸ Dependencies

- **Python 3.8+**: Modern Python features and type hints
- **Requests**: HTTP library for web crawling
- **BeautifulSoup4**: HTML parsing and text extraction
- **lxml**: Fast XML/HTML parser
- **Pytest**: Testing framework with coverage
- **JSON**: Configuration and data storage

## ğŸ¯ Usage

### Quick Start

Run the complete pipeline with default settings:

```sh
python main.py auto
```

This will:
1. Crawl configured websites (20 pages each)
2. Build TF-IDF index
3. Start interactive search mode

### Manual Control

**Crawl websites:**
```sh
python main.py crawl --urls "https://example.com" --max-pages 50
```

**Build search index:**
```sh
python main.py index
```

## ğŸ” **Search for Content** - Main Feature

**Search for content:**
```sh
python main.py search "Python web development"
```

**Interactive Search Mode:**
```sh
python main.py search
# Then enter queries interactively
```

**Advanced Search Options:**
```sh
# Search with custom result limit
python main.py search "machine learning" --max-results 20

# Search with specific scoring
python main.py search "web development" --algorithm tfidf

# Search with filters
python main.py search "Python tutorial" --domain docs.python.org
```

**Get system statistics:**
```sh
python main.py stats
```

### Example Session

```txt
$ python main.py auto
ğŸš€ Auto-setup: Loading seed URLs and crawling...
ğŸ•·ï¸  Setting up web crawler...
âœ… Crawler ready for 20 URLs, max 20 pages each, delay: 0.005s

ğŸ•·ï¸  Starting web crawling...
ğŸ“„ Crawling: https://stackoverflow.com
ğŸ“„ Crawling: https://developer.mozilla.org
ğŸ“„ Crawling: https://docs.python.org
...
âœ… Crawling completed successfully!

ğŸ“š Setting up indexer...
âœ… Indexer ready (data: data/pages, index: index/data)

ğŸ”§ Building search index...
ğŸ“Š Processing 245 documents...
ğŸ“Š Computing TF-IDF scores...
âœ… Index built successfully!

ğŸ” Setting up query engine...
âœ… Query engine ready

ğŸ” Enter your search query (or 'quit' to exit):
> Python web development

ğŸ“‹ Search Results for "Python web development":
1. [Score: 0.85] Flask Web Development Tutorial
   https://docs.python.org/3/tutorial/web.html
   Flask is a lightweight web framework for Python...

2. [Score: 0.72] Django Web Framework Guide
   https://docs.djangoproject.com/
   Django is a high-level Python web framework...
```

## âš™ï¸ Configuration

Edit `config.json` to customize behavior:

```json
{
  "seed_urls": [
    "https://stackoverflow.com",
    "https://developer.mozilla.org",
    "https://docs.python.org"
  ],
  "max_pages_per_url": 20,
  "crawl_delay": 0.005,
  "user_agent": "TechScopeBot/1.0",
  "data_directory": "data/pages",
  "index_directory": "index/data"
}
```

### Key Settings

- **seed_urls**: Starting URLs for crawling
- **max_pages_per_url**: Maximum pages to crawl per domain
- **crawl_delay**: Delay between requests (respects robots.txt)
- **user_agent**: Browser identification string

## ğŸ§ª Testing

Run the comprehensive test suite:

```sh
python run_tests.py
```

Or run individual test categories:

```sh
# Unit tests
pytest Tests/unit/

# Integration tests  
pytest Tests/integration/

# Performance tests
pytest Tests/performance/

# Edge cases
pytest Tests/edge_cases/
```

### Test Coverage

- **Crawler Tests**: URL parsing, HTML extraction, link discovery
- **Indexer Tests**: TF-IDF calculations, document processing
- **Query Tests**: Search algorithms, result ranking
- **Integration Tests**: End-to-end workflow validation
- **Performance Tests**: Large dataset handling
- **Edge Cases**: Error handling, malformed data

## ğŸ”§ Development

1. **Fork this repo**
2. **Create a feature branch**
   ```sh
   git checkout -b feature/my-improvement
   ```
3. **Install development dependencies**
   ```sh
   pip install -r requirements.txt
   ```
4. **Make your changes & test**
   ```sh
   python run_tests.py
   ```
5. **Commit & push**
   ```sh
   git commit -am "Add awesome feature"
   git push origin feature/my-improvement
   ```

## ğŸ—ï¸ Architecture

### Core Components

**Web Crawler (`crawler/`)**
- Multi-threaded web crawling
- Respects robots.txt and crawl delays
- Extracts text content and metadata
- Stores HTML and metadata files

**Indexer (`index/`)**
- Text preprocessing and tokenization
- TF-IDF score calculation
- Inverted index construction
- Document metadata management

**Query Engine (`query/`)**
- Query preprocessing and tokenization
- Cosine similarity calculation
- Result ranking and formatting
- Search result presentation

### Data Flow

```
URLs â†’ Crawler â†’ HTML Files â†’ Indexer â†’ TF-IDF Index â†’ Query Engine â†’ Search Results
```

## ğŸ“ What I Learned

This project was built to understand search engine fundamentals and web crawling techniques. Key learnings include:

- **Web Crawling**: HTTP requests, HTML parsing, link extraction
- **Information Retrieval**: TF-IDF algorithm, inverted indices
- **Text Processing**: Tokenization, stemming, stop word removal
- **Search Algorithms**: Cosine similarity, ranking algorithms
- **System Design**: Modular architecture, data flow optimization
- **Testing**: Comprehensive test coverage, edge case handling

By implementing a complete search engine from scratch, I gained deep insights into how modern search engines work and the challenges of web-scale information retrieval.

## ğŸ“Š Performance

- **Crawling Speed**: ~100 pages/minute (with delays)
- **Indexing Speed**: ~500 documents/minute
- **Search Response**: <100ms for typical queries
- **Memory Usage**: Efficient streaming for large datasets

## ğŸ¤ Contributing

Contributions are welcome! Please read our contributing guidelines and ensure all tests pass before submitting pull requests.

## ğŸ“„ License

Distributed under the MIT License. See [LICENSE](./LICENSE) for details.

## ğŸ‘¨â€ğŸ’» Author

**TechScope Author** â€“ [GitHub](https://github.com/xxxxxxxx15339)

---

<div align="center">

**Built with â¤ï¸ for learning search engine technology**

</div>


